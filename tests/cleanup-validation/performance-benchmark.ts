/**
 * Performance Benchmark Framework for Cleanup Validation
 *
 * Measures performance impact of cleanup operations across all categories.
 * Provides baseline and post-cleanup metrics for comprehensive validation.
 */

import { execSync } from 'child_process';
import { performance } from 'perf_hooks';
import { statSync, writeFileSync, readFileSync, existsSync } from 'fs';
import { join } from 'path';

export interface PerformanceMetrics {
  // Build Performance
  buildTime: number; // milliseconds
  typeCheckTime: number; // milliseconds
  devServerStartTime: number; // milliseconds

  // Bundle Analysis
  bundleSize: {
    total: number; // bytes
    packages: Record<string, number>;
    assets: number;
    chunks: Record<string, number>;
  };

  // Database Performance
  migrationTime: number; // milliseconds
  queryPerformance: {
    averageQueryTime: number;
    slowQueries: Array<{ query: string; time: number }>;
  };

  // Code Analysis Performance
  analysisTime: {
    knip: number;
    tsPrune: number;
    depcheck: number;
    madge: number;
  };

  // Memory Usage
  memoryUsage: {
    heapUsed: number;
    heapTotal: number;
    external: number;
    rss: number;
  };

  // File System Metrics
  fileMetrics: {
    totalFiles: number;
    totalLines: number;
    averageFileSize: number;
  };

  timestamp: string;
  environment: string;
  commit: string;
}

export interface BenchmarkResult {
  baseline: PerformanceMetrics;
  postCleanup: PerformanceMetrics;
  improvements: {
    buildTimeImprovement: number; // percentage
    bundleSizeReduction: number; // percentage
    typeCheckImprovement: number; // percentage
    memoryReduction: number; // percentage
  };
  regressions: Array<{
    metric: string;
    impact: number; // percentage
    threshold: number;
  }>;
}

export class PerformanceBenchmark {
  private metricsDir = '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks/tests/cleanup-validation/metrics';

  constructor() {
    // Ensure metrics directory exists
    if (!existsSync(this.metricsDir)) {
      execSync(`mkdir -p ${this.metricsDir}`);
    }
  }

  /**
   * Run complete performance benchmark
   */
  async runBenchmark(): Promise<PerformanceMetrics> {
    console.log('üîç Running performance benchmark...');

    const startTime = performance.now();

    // Get current environment info
    const environment = process.env.NODE_ENV || 'development';
    const commit = this.getCurrentCommit();

    // Run all benchmark tests
    const metrics: PerformanceMetrics = {
      buildTime: await this.measureBuildTime(),
      typeCheckTime: await this.measureTypeCheckTime(),
      devServerStartTime: await this.measureDevServerStart(),
      bundleSize: await this.analyzeBundleSize(),
      migrationTime: await this.measureMigrationTime(),
      queryPerformance: await this.measureQueryPerformance(),
      analysisTime: await this.measureAnalysisTime(),
      memoryUsage: this.measureMemoryUsage(),
      fileMetrics: await this.measureFileMetrics(),
      timestamp: new Date().toISOString(),
      environment,
      commit,
    };

    const totalTime = performance.now() - startTime;
    console.log(`‚úÖ Benchmark completed in ${Math.round(totalTime)}ms`);

    return metrics;
  }

  /**
   * Save baseline metrics
   */
  async saveBaseline(): Promise<PerformanceMetrics> {
    console.log('üìä Establishing performance baseline...');

    const metrics = await this.runBenchmark();
    const baselineFile = join(this.metricsDir, 'baseline-performance.json');

    writeFileSync(baselineFile, JSON.stringify(metrics, null, 2));
    console.log(`üíæ Baseline saved to: ${baselineFile}`);

    return metrics;
  }

  /**
   * Run post-cleanup benchmark and compare with baseline
   */
  async compareWithBaseline(): Promise<BenchmarkResult> {
    console.log('üîÑ Running post-cleanup benchmark...');

    const postCleanup = await this.runBenchmark();
    const baselineFile = join(this.metricsDir, 'baseline-performance.json');

    if (!existsSync(baselineFile)) {
      throw new Error('Baseline metrics not found. Run saveBaseline() first.');
    }

    const baseline: PerformanceMetrics = JSON.parse(readFileSync(baselineFile, 'utf8'));

    // Calculate improvements and regressions
    const improvements = this.calculateImprovements(baseline, postCleanup);
    const regressions = this.detectRegressions(baseline, postCleanup);

    const result: BenchmarkResult = {
      baseline,
      postCleanup,
      improvements,
      regressions,
    };

    // Save comparison results
    const comparisonFile = join(this.metricsDir, 'performance-comparison.json');
    writeFileSync(comparisonFile, JSON.stringify(result, null, 2));

    return result;
  }

  private async measureBuildTime(): Promise<number> {
    console.log('  ‚è±Ô∏è Measuring build time...');

    const startTime = performance.now();

    try {
      execSync('pnpm build', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
    } catch (error) {
      console.warn('Build failed, using estimate:', error.message);
      return -1; // Indicate failure
    }

    return performance.now() - startTime;
  }

  private async measureTypeCheckTime(): Promise<number> {
    console.log('  ‚è±Ô∏è Measuring TypeScript type check time...');

    const startTime = performance.now();

    try {
      execSync('pnpm typecheck', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
    } catch (error) {
      console.warn('Type check failed, using estimate:', error.message);
      return -1; // Indicate failure
    }

    return performance.now() - startTime;
  }

  private async measureDevServerStart(): Promise<number> {
    console.log('  ‚è±Ô∏è Measuring dev server start time...');

    // Since we can't actually start dev server in test, simulate measurement
    // In real implementation, this would start dev server and measure time to ready
    return 3000; // Simulated 3 second start time
  }

  private async analyzeBundleSize(): Promise<PerformanceMetrics['bundleSize']> {
    console.log('  üì¶ Analyzing bundle size...');

    const bundleSize = {
      total: 0,
      packages: {} as Record<string, number>,
      assets: 0,
      chunks: {} as Record<string, number>,
    };

    try {
      // Get package sizes from node_modules
      const packages = ['api', 'db', 'lib', 'worker'];
      for (const pkg of packages) {
        const packagePath = `/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks/packages/${pkg}`;
        if (existsSync(packagePath)) {
          const size = this.getDirectorySize(packagePath);
          bundleSize.packages[pkg] = size;
          bundleSize.total += size;
        }
      }

      // Get app size
      const appPath = '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks/apps/web';
      if (existsSync(appPath)) {
        const appSize = this.getDirectorySize(appPath);
        bundleSize.packages['web'] = appSize;
        bundleSize.total += appSize;
      }

    } catch (error) {
      console.warn('Bundle analysis failed:', error.message);
    }

    return bundleSize;
  }

  private async measureMigrationTime(): Promise<number> {
    console.log('  üóÑÔ∏è Measuring migration time...');

    // Simulate migration time measurement
    // In real implementation, this would run actual migrations
    return 500; // Simulated 500ms migration time
  }

  private async measureQueryPerformance(): Promise<PerformanceMetrics['queryPerformance']> {
    console.log('  üîç Measuring query performance...');

    // Simulate query performance measurement
    // In real implementation, this would run actual database queries
    return {
      averageQueryTime: 50, // 50ms average
      slowQueries: [],
    };
  }

  private async measureAnalysisTime(): Promise<PerformanceMetrics['analysisTime']> {
    console.log('  üîé Measuring analysis tool performance...');

    const analysisTime = {
      knip: 0,
      tsPrune: 0,
      depcheck: 0,
      madge: 0,
    };

    // Measure knip
    try {
      const startTime = performance.now();
      execSync('pnpm analysis:dead-code', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
      analysisTime.knip = performance.now() - startTime;
    } catch (error) {
      console.warn('Knip analysis failed:', error.message);
      analysisTime.knip = -1;
    }

    // Measure ts-prune
    try {
      const startTime = performance.now();
      execSync('pnpm analysis:ts-prune', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
      analysisTime.tsPrune = performance.now() - startTime;
    } catch (error) {
      console.warn('ts-prune analysis failed:', error.message);
      analysisTime.tsPrune = -1;
    }

    // Measure depcheck
    try {
      const startTime = performance.now();
      execSync('pnpm analysis:deps', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
      analysisTime.depcheck = performance.now() - startTime;
    } catch (error) {
      console.warn('Depcheck analysis failed:', error.message);
      analysisTime.depcheck = -1;
    }

    // Measure madge
    try {
      const startTime = performance.now();
      execSync('pnpm analysis:circular', {
        stdio: 'pipe',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      });
      analysisTime.madge = performance.now() - startTime;
    } catch (error) {
      console.warn('Madge analysis failed:', error.message);
      analysisTime.madge = -1;
    }

    return analysisTime;
  }

  private measureMemoryUsage(): PerformanceMetrics['memoryUsage'] {
    const memUsage = process.memoryUsage();
    return {
      heapUsed: memUsage.heapUsed,
      heapTotal: memUsage.heapTotal,
      external: memUsage.external,
      rss: memUsage.rss,
    };
  }

  private async measureFileMetrics(): Promise<PerformanceMetrics['fileMetrics']> {
    console.log('  üìÅ Measuring file system metrics...');

    let totalFiles = 0;
    let totalLines = 0;
    let totalSize = 0;

    try {
      // Count TypeScript files
      const tsFiles = execSync(
        'find packages apps -name "*.ts" -o -name "*.tsx" | wc -l',
        {
          encoding: 'utf8',
          cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
        }
      ).trim();

      totalFiles = parseInt(tsFiles);

      // Count lines of code
      const lines = execSync(
        'find packages apps -name "*.ts" -o -name "*.tsx" | xargs wc -l | tail -1',
        {
          encoding: 'utf8',
          cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
        }
      ).trim();

      totalLines = parseInt(lines.split(/\s+/)[0]) || 0;

      // Calculate average file size
      if (totalFiles > 0) {
        totalSize = this.getDirectorySize('/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks/packages') +
                   this.getDirectorySize('/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks/apps');
      }

    } catch (error) {
      console.warn('File metrics calculation failed:', error.message);
    }

    return {
      totalFiles,
      totalLines,
      averageFileSize: totalFiles > 0 ? totalSize / totalFiles : 0,
    };
  }

  private getDirectorySize(dirPath: string): number {
    try {
      if (!existsSync(dirPath)) return 0;

      const output = execSync(`du -sb "${dirPath}"`, { encoding: 'utf8' });
      return parseInt(output.split('\t')[0]);
    } catch {
      return 0;
    }
  }

  private getCurrentCommit(): string {
    try {
      return execSync('git rev-parse HEAD', {
        encoding: 'utf8',
        cwd: '/Users/benjaminwierzbanowski/Code/epic-cleanupandcodechecks'
      }).trim();
    } catch {
      return 'unknown';
    }
  }

  private calculateImprovements(baseline: PerformanceMetrics, postCleanup: PerformanceMetrics) {
    const improvement = (before: number, after: number) => {
      if (before <= 0 || after <= 0) return 0;
      return ((before - after) / before) * 100;
    };

    return {
      buildTimeImprovement: improvement(baseline.buildTime, postCleanup.buildTime),
      bundleSizeReduction: improvement(baseline.bundleSize.total, postCleanup.bundleSize.total),
      typeCheckImprovement: improvement(baseline.typeCheckTime, postCleanup.typeCheckTime),
      memoryReduction: improvement(baseline.memoryUsage.heapUsed, postCleanup.memoryUsage.heapUsed),
    };
  }

  private detectRegressions(baseline: PerformanceMetrics, postCleanup: PerformanceMetrics) {
    const regressions = [];
    const threshold = 5; // 5% regression threshold

    const checkRegression = (name: string, before: number, after: number, thresholdPercent = threshold) => {
      if (before <= 0 || after <= 0) return;

      const regression = ((after - before) / before) * 100;
      if (regression > thresholdPercent) {
        regressions.push({
          metric: name,
          impact: regression,
          threshold: thresholdPercent,
        });
      }
    };

    checkRegression('Build Time', baseline.buildTime, postCleanup.buildTime);
    checkRegression('Type Check Time', baseline.typeCheckTime, postCleanup.typeCheckTime);
    checkRegression('Dev Server Start', baseline.devServerStartTime, postCleanup.devServerStartTime);
    checkRegression('Memory Usage', baseline.memoryUsage.heapUsed, postCleanup.memoryUsage.heapUsed);

    return regressions;
  }

  /**
   * Generate human-readable benchmark report
   */
  generateReport(result: BenchmarkResult): string {
    const { baseline, postCleanup, improvements, regressions } = result;

    let report = `# Performance Benchmark Report\n\n`;
    report += `**Generated**: ${new Date().toISOString()}\n`;
    report += `**Baseline Commit**: ${baseline.commit}\n`;
    report += `**Post-Cleanup Commit**: ${postCleanup.commit}\n\n`;

    // Performance Improvements
    report += `## üöÄ Performance Improvements\n\n`;
    if (improvements.buildTimeImprovement > 0) {
      report += `- **Build Time**: ${improvements.buildTimeImprovement.toFixed(1)}% faster\n`;
    }
    if (improvements.bundleSizeReduction > 0) {
      report += `- **Bundle Size**: ${improvements.bundleSizeReduction.toFixed(1)}% smaller\n`;
    }
    if (improvements.typeCheckImprovement > 0) {
      report += `- **Type Check**: ${improvements.typeCheckImprovement.toFixed(1)}% faster\n`;
    }
    if (improvements.memoryReduction > 0) {
      report += `- **Memory Usage**: ${improvements.memoryReduction.toFixed(1)}% reduction\n`;
    }

    // Performance Regressions
    if (regressions.length > 0) {
      report += `\n## ‚ö†Ô∏è Performance Regressions\n\n`;
      for (const regression of regressions) {
        report += `- **${regression.metric}**: ${regression.impact.toFixed(1)}% slower (threshold: ${regression.threshold}%)\n`;
      }
    }

    // Detailed Metrics
    report += `\n## üìä Detailed Metrics\n\n`;
    report += `### Build Performance\n`;
    report += `| Metric | Baseline | Post-Cleanup | Change |\n`;
    report += `|--------|----------|--------------|--------|\n`;
    report += `| Build Time | ${baseline.buildTime.toFixed(0)}ms | ${postCleanup.buildTime.toFixed(0)}ms | ${((postCleanup.buildTime - baseline.buildTime) / baseline.buildTime * 100).toFixed(1)}% |\n`;
    report += `| Type Check | ${baseline.typeCheckTime.toFixed(0)}ms | ${postCleanup.typeCheckTime.toFixed(0)}ms | ${((postCleanup.typeCheckTime - baseline.typeCheckTime) / baseline.typeCheckTime * 100).toFixed(1)}% |\n`;

    report += `\n### Bundle Size\n`;
    report += `| Package | Baseline | Post-Cleanup | Change |\n`;
    report += `|---------|----------|--------------|--------|\n`;
    for (const [pkg, size] of Object.entries(baseline.bundleSize.packages)) {
      const postSize = postCleanup.bundleSize.packages[pkg] || 0;
      const change = size > 0 ? ((postSize - size) / size * 100) : 0;
      report += `| ${pkg} | ${(size / 1024).toFixed(1)}KB | ${(postSize / 1024).toFixed(1)}KB | ${change.toFixed(1)}% |\n`;
    }

    return report;
  }
}

// Export helper function for running benchmarks
export async function runPerformanceBenchmark(): Promise<BenchmarkResult> {
  const benchmark = new PerformanceBenchmark();
  return await benchmark.compareWithBaseline();
}

export async function establishBaseline(): Promise<PerformanceMetrics> {
  const benchmark = new PerformanceBenchmark();
  return await benchmark.saveBaseline();
}